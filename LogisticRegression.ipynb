{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "- Explore the differences between batch and stochastic gradient descent\n",
    "- Implement K-Folds Cross-Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imblearn\n",
    "data = pd.read_csv('./stroke_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find and fill null values with averages (BMI has 201 null values)\n",
    "avg = data['bmi'].mean()\n",
    "data.bmi=(data.bmi.fillna(avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give numerical values to categorical variables\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th colspan=2>work_type</th>\n",
    "            <th colspan=2>gender</th>\n",
    "            <th colspan=2>Residence_type</th>\n",
    "            <th colspan=2>smoking_status</th>\n",
    "            <th colspan=2>ever_married</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Private</td>\n",
    "            <td>0</td>\n",
    "            <td>Male</td>\n",
    "            <td>0</td>\n",
    "            <td>Urban</td>\n",
    "            <td>0</td>\n",
    "            <td>formerly smoked</td>\n",
    "            <td>0</td>\n",
    "            <td>Yes</td>\n",
    "            <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Self-employed</td>\n",
    "            <td>1</td>\n",
    "            <td>Female</td>\n",
    "            <td>1</td>\n",
    "            <td>Rural</td>\n",
    "            <td>1</td>\n",
    "            <td>never smoked</td>\n",
    "            <td>1</td>\n",
    "            <td>No</td>\n",
    "            <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Govt_job</td>\n",
    "            <td>2</td>\n",
    "            <td>smokes</td>\n",
    "            <td>2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>children</td>\n",
    "            <td>3</td>\n",
    "            <td>Unknown</td>\n",
    "            <td>3</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Never_worked</td>\n",
    "            <td>4</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['work_type'] = data['work_type'].map({'Private':0, 'Self-employed': 1, 'Govt_job':2, 'children':3, 'Never_worked':4})\n",
    "data['gender'] = data['gender'].map({'Male':0, 'Female':1})\n",
    "data['Residence_type'] = data['Residence_type'].map({'Urban':0, 'Rural':1})\n",
    "data['smoking_status'] = data['smoking_status'].map({'formerly smoked':0, 'never smoked':1, 'smokes':2, 'Unknown':3})\n",
    "data['ever_married'] = data['ever_married'].map({'Yes':0, 'No':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide dataset into features and labels\n",
    "#drop ID because it's not necessary for analysis\n",
    "X = data[['age','hypertension','heart_disease','ever_married','Residence_type','avg_glucose_level','bmi','gender','work_type','smoking_status']]\n",
    "y = data['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chathuminiabeyratna/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#replace null values again (1 in gender)\n",
    "X.gender=(X.gender.fillna(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizes the data using the mean and standard deviation\n",
    "mean = np.mean(X, axis = 0)\n",
    "std = np.std(X, axis = 0, ddof=1)\n",
    "s_X = (X - mean)/std\n",
    "\n",
    "#add bias feature\n",
    "bias = (np.ones((s_X.shape[0], 1)))\n",
    "s_X = np.append(s_X, bias, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "s_X, y = smote.fit_resample(s_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test=train_test_split(s_X,y,test_size=0.33,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "#Initialize the parameters of θ using random values in the range [-1, 1]\n",
    "random.seed(0)\n",
    "thetas = np.random.uniform(-1, 1, 11)\n",
    "\n",
    "#variables \n",
    "n= 0.01 #learning rate\n",
    "count = pd.DataFrame()\n",
    "percent_change = 1\n",
    "count_num = 1\n",
    "cost = 1\n",
    "m = X_train.shape[0]\n",
    "#y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, thetas):\n",
    "    return (1/(1 + math.e ** -(x @ thetas)))\n",
    "\n",
    "def gradient(X_train, y_train, thetas):\n",
    "    sig = sigmoid(X_train, thetas)\n",
    "    gradient = (X_train.T @ (sig - y_train))\n",
    "    return gradient\n",
    "    \n",
    "#predictions\n",
    "def prediction(y_test, X_test, thetas):\n",
    "    size_test = y_test.shape[0]\n",
    "    predictions = np.zeros(size_test)\n",
    "    TP = FP = TN = FN = accuracy = 0\n",
    "\n",
    "    #find probability for 1 and 0\n",
    "    for a in range(size_test):\n",
    "        p_1 = 1/(1 + math.e ** -(X_test[a] @ thetas))\n",
    "        p_0 = 1 - p_1\n",
    "        if(p_1 > p_0):\n",
    "            predictions[a] = 1\n",
    "        else:\n",
    "            predictions[a] = 0\n",
    "\n",
    "    #find TP, FP, TN, FN\n",
    "    for a in range(size_test):\n",
    "        if (predictions[a] == 1):\n",
    "            if (predictions[a] == y_test.iloc[a]):\n",
    "                TP = TP + 1\n",
    "                accuracy = accuracy + 1\n",
    "            else:\n",
    "                FP = FP + 1 \n",
    "        else:\n",
    "            if(predictions[a] == y_test.iloc[a]):\n",
    "                TN = TN + 1\n",
    "                accuracy = accuracy + 1\n",
    "            else:\n",
    "                FN = FN + 1\n",
    "\n",
    "    #precision, recall, f measure, accuracy\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    F1 = (2*precision*recall)/(precision + recall)\n",
    "    accuracy = accuracy/size_test\n",
    "\n",
    "    print(\"Accuracy: \", accuracy* 100)\n",
    "    print(\"Precision: \", precision * 100)\n",
    "    print(\"Recall: \", recall* 100)\n",
    "    print(\"F-measure: \", F1* 100)\n",
    "    print(\"TP: \", TP,\"; FP: \", FP, \"; TN: \", TN, \"; FN: \", FN)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticBGD(X_train, y_train, X_test, y_test, n, m):\n",
    "    count_num = 0\n",
    "    new_cost = 0\n",
    "    percent_change = 1\n",
    "    thetas = np.random.uniform(-1, 1, 11)\n",
    "    #Terminate when absolute value change of loss on the data is\n",
    "    #less than 2−23, or after 1500 iterations have passed (whichever occurs first).\n",
    "    while (percent_change > (2 ** -23)):\n",
    "        if (count_num == 1500):\n",
    "            break\n",
    "\n",
    "        #batch gradient descent\n",
    "        thetas = thetas - ((n/m) * gradient(X_train, y_train, thetas))\n",
    "\n",
    "        #cost\n",
    "        total_cost = -np.sum((1/m) * ((y_train * np.log(sigmoid(X_train, thetas) + epsilon)) + (1 - y_train) * np.log(1 - sigmoid(X_train,thetas) + epsilon)))\n",
    "\n",
    "        #percent change\n",
    "        percent_change = abs((new_cost - total_cost)/total_cost)\n",
    "        new_cost = total_cost\n",
    "\n",
    "        count_num = count_num + 1\n",
    "\n",
    "    print(\"Thetas from batch gradient descent that minimize the loss function: \", thetas, \"\\n\")\n",
    "    prediction(y_test, X_test, thetas)\n",
    "\n",
    "def logisticSGD(X_train, y_train, y_test, X_test, n, m):\n",
    "    stoch_X_train = X_train\n",
    "    stoch_y_train = y_train\n",
    "    thetas = np.random.uniform(-1, 1, 11)\n",
    "    new_cost = 1\n",
    "    percent_change = 1\n",
    "    count_num = 1\n",
    "    \n",
    "    #Terminate when absolute value change of loss on the data is less than 2−23, or after 1500 iterations have passed.\n",
    "    while (percent_change > (2 ** -23)):\n",
    "        if (count_num == 1500):\n",
    "            break\n",
    "\n",
    "        #stochastic gradient descent\n",
    "        index = np.random.permutation(stoch_X_train.shape[0])\n",
    "        stoch_X_train = np.take(stoch_X_train,index,axis=0)\n",
    "        stoch_y_train = np.take(stoch_y_train,index,axis=0)\n",
    "        thetas = thetas - ((n/m) * gradient(stoch_X_train, stoch_y_train, thetas))\n",
    "\n",
    "        #cost\n",
    "        total_cost = -np.sum((1/m) * (stoch_y_train * np.log(sigmoid(stoch_X_train, thetas) + epsilon)) + (1 - stoch_y_train) * np.log(1 - sigmoid(stoch_X_train,thetas) + epsilon))\n",
    "\n",
    "        #percent change\n",
    "        percent_change = abs((new_cost - total_cost)/total_cost)\n",
    "        new_cost = total_cost\n",
    "        count_num = count_num + 1\n",
    "\n",
    "    print(\"Thetas from stochastic gradient descent that minimize the loss function: \", thetas, \"\\n\")\n",
    "\n",
    "    prediction(y_test, X_test, thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "n = 0.01 #learning rate\n",
    "m = X_train.shape[0]\n",
    "#y_train = y_train.to_numpy()\n",
    "epsilon = 1e-5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetas from batch gradient descent that minimize the loss function:  [ 1.07242977  0.15636651  0.20384122  0.03998727 -0.00416046  0.13296319\n",
      "  0.08496215 -0.05319611  0.07767606 -0.12630771 -0.56085458] \n",
      "\n",
      "Accuracy:  77.40729199127455\n",
      "Precision:  73.42436974789915\n",
      "Recall:  86.45640074211502\n",
      "F-measure:  79.4092587333144\n",
      "TP:  1398 ; FP:  506 ; TN:  1086 ; FN:  219\n"
     ]
    }
   ],
   "source": [
    "logisticBGD(X_train, y_train, X_test, y_test, n, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetas from stochastic gradient descent that minimize the loss function:  [ 1.32529993  0.11633822  0.07637629 -0.12329115 -0.09782157  0.22873248\n",
      " -0.06294027 -0.0768626   0.20692756  0.02929375 -0.74286571] \n",
      "\n",
      "Accuracy:  78.43564973511997\n",
      "Precision:  74.20198848770278\n",
      "Recall:  87.69325912183055\n",
      "F-measure:  80.38548752834468\n",
      "TP:  1418 ; FP:  493 ; TN:  1099 ; FN:  199\n"
     ]
    }
   ],
   "source": [
    "logisticSGD(X_train, y_train, y_test, X_test, n, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7874727329386102\n",
      "Precision:  0.7660785429709732\n",
      "Recall:  0.8324056895485467\n",
      "F-measure:  0.7978660343805573\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "logistic_regression= LogisticRegression()\n",
    "logistic_regression.fit(X_train,y_train)\n",
    "y_pred=logistic_regression.predict(X_test)\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ',metrics.precision_score(y_test, y_pred,zero_division=0))\n",
    "print('Recall: ',metrics.recall_score(y_test, y_pred))\n",
    "print('F-measure: ',metrics.f1_score(y_test, y_pred,zero_division=0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
