{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imblearn\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./stroke_data.csv')\n",
    "#find and fill null values with averages (BMI has 201 null values)\n",
    "avg = data['bmi'].mean()\n",
    "data.bmi=(data.bmi.fillna(avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give numerical values to categorical variables\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th colspan=2>work_type</th>\n",
    "            <th colspan=2>gender</th>\n",
    "            <th colspan=2>Residence_type</th>\n",
    "            <th colspan=2>smoking_status</th>\n",
    "            <th colspan=2>ever_married</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Private</td>\n",
    "            <td>0</td>\n",
    "            <td>Male</td>\n",
    "            <td>0</td>\n",
    "            <td>Urban</td>\n",
    "            <td>0</td>\n",
    "            <td>formerly smoked</td>\n",
    "            <td>0</td>\n",
    "            <td>Yes</td>\n",
    "            <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Self-employed</td>\n",
    "            <td>1</td>\n",
    "            <td>Female</td>\n",
    "            <td>1</td>\n",
    "            <td>Rural</td>\n",
    "            <td>1</td>\n",
    "            <td>never smoked</td>\n",
    "            <td>1</td>\n",
    "            <td>No</td>\n",
    "            <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Govt_job</td>\n",
    "            <td>2</td>\n",
    "            <td>smokes</td>\n",
    "            <td>2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>children</td>\n",
    "            <td>3</td>\n",
    "            <td>Unknown</td>\n",
    "            <td>3</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Never_worked</td>\n",
    "            <td>4</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['work_type'] = data['work_type'].map({'Private':0, 'Self-employed': 1, 'Govt_job':2, 'children':3, 'Never_worked':4})\n",
    "data['gender'] = data['gender'].map({'Male':0, 'Female':1})\n",
    "data['Residence_type'] = data['Residence_type'].map({'Urban':0, 'Rural':1})\n",
    "data['smoking_status'] = data['smoking_status'].map({'formerly smoked':0, 'never smoked':1, 'smokes':2, 'Unknown':3})\n",
    "data['ever_married'] = data['ever_married'].map({'Yes':0, 'No':1})\n",
    "\n",
    "#divide dataset into features and labels\n",
    "#drop ID because it's not necessary for analysis\n",
    "X = data.iloc[:, 1:-1]\n",
    "y = data[['stroke']]\n",
    "\n",
    "#replace null values again (1 in gender)\n",
    "X.gender=(X.gender.fillna(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    #Standardizes the data using the mean and standard deviation\n",
    "    mean = np.mean(X, axis = 0)\n",
    "    std = np.std(X, axis = 0, ddof=1)\n",
    "    s_X = (X - mean)/std\n",
    "\n",
    "    #add bias feature\n",
    "    bias = (np.ones((s_X.shape[0], 1)))\n",
    "    s_X = np.append(s_X, bias, axis=1)\n",
    "    return s_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_X = standardize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "s_X, y = smote.fit_resample(s_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, thetas):\n",
    "    return (1/(1 + math.e ** -(x @ thetas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X_train, y_train, thetas): \n",
    "    sig = sigmoid(X_train, thetas)\n",
    "    gradient = (X_train.T @ (sig - y_train))\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticBGD(X_train, y_train, X_test, y_test, n, m, kfold):\n",
    "    count_num = 0\n",
    "    new_cost = 0\n",
    "    percent_change = 1\n",
    "    thetas = np.random.uniform(-1, 1, 11).reshape(11,1)\n",
    "    \n",
    "    #Terminate when absolute value change of loss on the data is\n",
    "    #less than 2−23, or after 1500 iterations have passed (whichever occurs first).\n",
    "    while (percent_change > (2 ** -23)):\n",
    "        if (count_num == 1500):\n",
    "            break\n",
    "\n",
    "        #batch gradient descent\n",
    "        thetas = thetas - ((n/m) * gradient(X_train, y_train, thetas))\n",
    "\n",
    "        #cost\n",
    "        total_cost = -np.sum((1/m) * ((y_train * np.log(sigmoid(X_train, thetas) + epsilon)) + (1 - y_train) * np.log(1 - sigmoid(X_train,thetas) + epsilon)))\n",
    "\n",
    "        #percent change\n",
    "        percent_change = abs((new_cost - total_cost)/total_cost)\n",
    "        new_cost = total_cost\n",
    "\n",
    "        count_num = count_num + 1\n",
    "\n",
    "    #print(\"Thetas from batch gradient descent that minimize the loss function: \", thetas, \"\\n\")\n",
    "    if(kfold == \"kfold\"):\n",
    "        accuracy, precision, recall, F1 = prediction(y_test, X_test, thetas, kfold)\n",
    "        return accuracy, precision, recall, F1\n",
    "    if(kfold == \"no\"):\n",
    "        prediction(y_test, X_test, thetas, kfold)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticSGD(X_train, y_train, y_test, X_test, n, m, kfold):\n",
    "    stoch_X_train = X_train\n",
    "    stoch_y_train = y_train\n",
    "    thetas = np.random.uniform(-1, 1, 11).reshape(11,1)\n",
    "    new_cost = 1\n",
    "    percent_change = 1\n",
    "    count_num = 1\n",
    "    \n",
    "    #Terminate when absolute value change of loss on the data is less than 2−23, or after 1500 iterations have passed.\n",
    "    while (percent_change > (2 ** -23)):\n",
    "        if (count_num == 1500):\n",
    "            break\n",
    "\n",
    "        #stochastic gradient descent\n",
    "        index = np.random.permutation(stoch_X_train.shape[0])\n",
    "        stoch_X_train = np.take(stoch_X_train,index,axis=0)\n",
    "        stoch_y_train = np.take(stoch_y_train,index,axis=0)\n",
    "        thetas = thetas - ((n/m) * gradient(stoch_X_train, stoch_y_train, thetas))\n",
    "\n",
    "        #cost\n",
    "        total_cost = -np.sum((1/m) * (stoch_y_train * np.log(sigmoid(stoch_X_train, thetas) + epsilon)) + (1 - stoch_y_train) * np.log(1 - sigmoid(stoch_X_train,thetas) + epsilon))\n",
    "\n",
    "        #percent change\n",
    "        percent_change = abs((new_cost - total_cost)/total_cost)\n",
    "        new_cost = total_cost\n",
    "        count_num = count_num + 1\n",
    "\n",
    "    #print(\"Thetas from stochastic gradient descent that minimize the loss function: \", thetas, \"\\n\")\n",
    "    if(kfold == \"kfold\"):\n",
    "        accuracy, precision, recall, F1 = prediction(y_test, X_test, thetas, kfold)\n",
    "        return accuracy, precision, recall, F1\n",
    "    if(kfold == \"no\"):\n",
    "        prediction(y_test, X_test, thetas, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Folds split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(data, numfolds):\n",
    "    dataset = data\n",
    "    data_folds = []\n",
    "    fold_size = int(dataset.shape[0] / numfolds)\n",
    "        \n",
    "    for i in range(numfolds):\n",
    "        fold = []\n",
    "        \n",
    "        #add random data to the folds\n",
    "        while len(fold) < fold_size: \n",
    "            index = random.randrange(dataset.shape[0])\n",
    "            # save data at index to fold \n",
    "            fold.append(dataset.iloc[index].values.tolist())\n",
    "            # delete data line from dataset\n",
    "            dataset = dataset.drop(index,axis = 0)  \n",
    "            dataset.reset_index(drop=True, inplace=True)\n",
    "        data_folds.append(np.asarray(fold))\n",
    "            \n",
    "    return data_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(data, model, kfold, f=5):\n",
    "    data=cv_split(data,f)\n",
    "    result=[]\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    F1 = []\n",
    "    \n",
    "    # determine training and test sets \n",
    "    for i in range(f):\n",
    "        r = list(range(f))\n",
    "        testi = data[i]\n",
    "        r.pop(i)\n",
    "        for j in r :\n",
    "            if j == r[0]:\n",
    "                traini = data[j]\n",
    "            else: \n",
    "                traini=np.concatenate((traini,data[j]), axis=0)\n",
    "        \n",
    "        k_train_x = traini[:, 0:-1]\n",
    "        k_train_y = traini[:, -1]\n",
    "        k_train_y = k_train_y.reshape(k_train_y.shape[0],1)\n",
    "        k_test_x = testi[:, 0:-1]\n",
    "        k_test_y = pd.DataFrame(testi[:, -1])\n",
    "        \n",
    "        if(model == \"batch\"):\n",
    "            accuracy1, precision1, recall1, F11 = logisticBGD(k_train_x, k_train_y, k_test_x, k_test_y, n, m, kfold)\n",
    "            accuracy.append(accuracy1)\n",
    "            precision.append(precision1)\n",
    "            recall.append(recall1)\n",
    "            F1.append(F11)\n",
    "        if(model == \"stochastic\"):\n",
    "            accuracy1, precision1, recall1, F11 = logisticSGD(k_train_x, k_train_y, k_test_y, k_test_x, n, m, kfold)\n",
    "            accuracy.append(accuracy1)\n",
    "            precision.append(precision1)\n",
    "            recall.append(recall1)\n",
    "            F1.append(F11)\n",
    "    print(\"Accuracies: \", np.array(accuracy)*100)\n",
    "    print(\"Precisions: \", np.array(precision)*100)\n",
    "    print(\"Recalls: \", np.array(recall)*100)\n",
    "    print(\"F-measures: \", np.array(F1)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(y_test, X_test, thetas, kfold):\n",
    "    size_test = y_test.shape[0]\n",
    "    predictions = np.zeros(size_test)\n",
    "    TP = FP = TN = FN = accuracy = 0\n",
    "\n",
    "    #find probability for 1 and 0\n",
    "    for a in range(size_test):\n",
    "        p_1 = 1/(1 + math.e ** -(X_test[a] @ thetas))\n",
    "        p_0 = 1 - p_1\n",
    "        if(p_1 > p_0):\n",
    "            predictions[a] = 1\n",
    "        else:\n",
    "            predictions[a] = 0\n",
    "\n",
    "    #find TP, FP, TN, FN\n",
    "    for a in range(size_test):\n",
    "        if (predictions[a] == 1):\n",
    "            if (predictions[a] == y_test.iloc[a][0]):\n",
    "                TP = TP + 1\n",
    "                accuracy = accuracy + 1\n",
    "            else:\n",
    "                FP = FP + 1 \n",
    "        else:\n",
    "            if(predictions[a] == y_test.iloc[a][0]):\n",
    "                TN = TN + 1\n",
    "                accuracy = accuracy + 1\n",
    "            else:\n",
    "                FN = FN + 1\n",
    "\n",
    "    #precision, recall, f measure, accuracy\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    F1 = (2*precision*recall)/(precision + recall)\n",
    "    accuracy = accuracy/size_test\n",
    "    \n",
    "    if(kfold == \"kfold\"):\n",
    "        return accuracy, precision, recall, F1\n",
    "    \n",
    "    else:\n",
    "        print(\"Accuracy: \", accuracy* 100)\n",
    "        print(\"Precision: \", precision * 100)\n",
    "        print(\"Recall: \", recall* 100)\n",
    "        print(\"F-measure: \", F1* 100)\n",
    "        print(\"TP: \", TP,\"; FP: \", FP, \"; TN: \", TN, \"; FN: \", FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Without K-Folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test=train_test_split(s_X,y,test_size=0.33,random_state=0)\n",
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "n = 0.01 #learning rate\n",
    "count = pd.DataFrame()\n",
    "percent_change = 1\n",
    "count_num = 1\n",
    "cost = 1\n",
    "m = X_train.shape[0]\n",
    "#y_train = y_train.to_numpy()\n",
    "epsilon = 1e-5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  78.43564973511997\n",
      "Precision:  75.70872707059478\n",
      "Recall:  84.2300556586271\n",
      "F-measure:  79.74238875878221\n",
      "TP:  1362 ; FP:  437 ; TN:  1155 ; FN:  255\n"
     ]
    }
   ],
   "source": [
    "logisticBGD(X_train, y_train, X_test, y_test, n, m, \"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  78.37332502337176\n",
      "Precision:  74.82517482517483\n",
      "Recall:  86.0235003092146\n",
      "F-measure:  80.03452243958573\n",
      "TP:  1391 ; FP:  468 ; TN:  1124 ; FN:  226\n"
     ]
    }
   ],
   "source": [
    "logisticSGD(X_train, y_train, y_test, X_test, n, m, \"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7834216266749766\n",
      "Precision:  0.7640320733104238\n",
      "Recall:  0.8249845392702535\n",
      "F-measure:  0.7933392804044008\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train,X_test, y_train,y_test=train_test_split(s_X,y,test_size=0.33,random_state=0)\n",
    "y_train = y_train.values.ravel()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "\n",
    "#y_train = y_train.ravel()\n",
    "logistic_regression= LogisticRegression()\n",
    "logistic_regression.fit(X_train,y_train)\n",
    "y_pred=logistic_regression.predict(X_test)\n",
    "y_test = y_test.values\n",
    "y_test = y_test.reshape(3209,)\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ',metrics.precision_score(y_test, y_pred,zero_division=0))\n",
    "print('Recall: ',metrics.recall_score(y_test, y_pred))\n",
    "print('F-measure: ',metrics.f1_score(y_test, y_pred,zero_division=0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results With K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.append(s_X, y, axis=1)\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Batch Gradient Descent, k-folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:  [77.52057613 79.218107   78.49794239 80.19547325 77.52057613]\n",
      "Precisions:  [72.65556529 76.93693694 74.64920486 77.65363128 74.52574526]\n",
      "Recalls:  [86.89727463 85.22954092 84.44444444 85.18896834 84.18367347]\n",
      "F-measures:  [79.14081146 80.87121212 79.24528302 81.24695567 79.0608529 ]\n"
     ]
    }
   ],
   "source": [
    "kfold(data, \"batch\", \"kfold\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Stochastic Gradient Descent, k-folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:  [77.41769547 78.24074074 79.16666667 78.7037037  77.98353909]\n",
      "Precisions:  [72.88888889 74.50805009 76.17421008 74.375      73.42781222]\n",
      "Recalls:  [85.95387841 85.78784758 87.62278978 86.77083333 86.62486938]\n",
      "F-measures:  [78.88407888 79.75107707 81.4984011  80.09615385 79.4822627 ]\n"
     ]
    }
   ],
   "source": [
    "kfold(data, \"stochastic\", \"kfold\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
