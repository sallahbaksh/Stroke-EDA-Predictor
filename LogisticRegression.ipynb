{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imblearn\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./stroke_data.csv')\n",
    "#find and fill null values with averages (BMI has 201 null values)\n",
    "avg = data['bmi'].mean()\n",
    "data.bmi=(data.bmi.fillna(avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give numerical values to categorical variables\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th colspan=2>work_type</th>\n",
    "            <th colspan=2>gender</th>\n",
    "            <th colspan=2>Residence_type</th>\n",
    "            <th colspan=2>smoking_status</th>\n",
    "            <th colspan=2>ever_married</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Private</td>\n",
    "            <td>0</td>\n",
    "            <td>Male</td>\n",
    "            <td>0</td>\n",
    "            <td>Urban</td>\n",
    "            <td>0</td>\n",
    "            <td>formerly smoked</td>\n",
    "            <td>0</td>\n",
    "            <td>Yes</td>\n",
    "            <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Self-employed</td>\n",
    "            <td>1</td>\n",
    "            <td>Female</td>\n",
    "            <td>1</td>\n",
    "            <td>Rural</td>\n",
    "            <td>1</td>\n",
    "            <td>never smoked</td>\n",
    "            <td>1</td>\n",
    "            <td>No</td>\n",
    "            <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Govt_job</td>\n",
    "            <td>2</td>\n",
    "            <td>smokes</td>\n",
    "            <td>2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>children</td>\n",
    "            <td>3</td>\n",
    "            <td>Unknown</td>\n",
    "            <td>3</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Never_worked</td>\n",
    "            <td>4</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['work_type'] = data['work_type'].map({'Private':0, 'Self-employed': 1, 'Govt_job':2, 'children':3, 'Never_worked':4})\n",
    "data['gender'] = data['gender'].map({'Male':0, 'Female':1})\n",
    "data['Residence_type'] = data['Residence_type'].map({'Urban':0, 'Rural':1})\n",
    "data['smoking_status'] = data['smoking_status'].map({'formerly smoked':0, 'never smoked':1, 'smokes':2, 'Unknown':3})\n",
    "data['ever_married'] = data['ever_married'].map({'Yes':0, 'No':1})\n",
    "\n",
    "#divide dataset into features and labels\n",
    "#drop ID because it's not necessary for analysis\n",
    "X = data.iloc[:, 1:-1]\n",
    "y = data[['stroke']]\n",
    "\n",
    "#replace null values again (1 in gender)\n",
    "X.gender=(X.gender.fillna(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    #Standardizes the data using the mean and standard deviation\n",
    "    mean = np.mean(X, axis = 0)\n",
    "    std = np.std(X, axis = 0, ddof=1)\n",
    "    s_X = (X - mean)/std\n",
    "\n",
    "    #add bias feature\n",
    "    bias = (np.ones((s_X.shape[0], 1)))\n",
    "    s_X = np.append(s_X, bias, axis=1)\n",
    "    return s_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_X = standardize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "s_X, y = smote.fit_resample(s_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, thetas):\n",
    "    return (1/(1 + math.e ** -(x @ thetas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X_train, y_train, thetas): \n",
    "    sig = sigmoid(X_train, thetas)\n",
    "    gradient = (X_train.T @ (sig - y_train))\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticBGD(X_train, y_train, X_test, y_test, n, m, kfold):\n",
    "    count_num = 0\n",
    "    new_cost = 0\n",
    "    percent_change = 1\n",
    "    thetas = np.random.uniform(-1, 1, 11).reshape(11,1)\n",
    "    \n",
    "    #Terminate when absolute value change of loss on the data is\n",
    "    #less than 2−23, or after 1500 iterations have passed (whichever occurs first).\n",
    "    while (percent_change > (2 ** -23)):\n",
    "        if (count_num == 1500):\n",
    "            break\n",
    "\n",
    "        #batch gradient descent\n",
    "        thetas = thetas - ((n/m) * gradient(X_train, y_train, thetas))\n",
    "\n",
    "        #cost\n",
    "        total_cost = -np.sum((1/m) * ((y_train * np.log(sigmoid(X_train, thetas) + epsilon)) + (1 - y_train) * np.log(1 - sigmoid(X_train,thetas) + epsilon)))\n",
    "\n",
    "        #percent change\n",
    "        percent_change = abs((new_cost - total_cost)/total_cost)\n",
    "        new_cost = total_cost\n",
    "\n",
    "        count_num = count_num + 1\n",
    "\n",
    "    #print(\"Thetas from batch gradient descent that minimize the loss function: \", thetas, \"\\n\")\n",
    "    if(kfold == \"kfold\"):\n",
    "        accuracy, precision, recall, F1 = prediction(y_test, X_test, thetas, kfold)\n",
    "        return accuracy, precision, recall, F1\n",
    "    if(kfold == \"no\"):\n",
    "        prediction(y_test, X_test, thetas, kfold)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticSGD(X_train, y_train, y_test, X_test, n, m, kfold):\n",
    "    stoch_X_train = X_train\n",
    "    stoch_y_train = y_train\n",
    "    thetas = np.random.uniform(-1, 1, 11).reshape(11,1)\n",
    "    new_cost = 1\n",
    "    percent_change = 1\n",
    "    count_num = 1\n",
    "    \n",
    "    #Terminate when absolute value change of loss on the data is less than 2−23, or after 1500 iterations have passed.\n",
    "    while (percent_change > (2 ** -23)):\n",
    "        if (count_num == 1500):\n",
    "            break\n",
    "\n",
    "        #stochastic gradient descent\n",
    "        index = np.random.permutation(stoch_X_train.shape[0])\n",
    "        stoch_X_train = np.take(stoch_X_train,index,axis=0)\n",
    "        stoch_y_train = np.take(stoch_y_train,index,axis=0)\n",
    "        thetas = thetas - ((n/m) * gradient(stoch_X_train, stoch_y_train, thetas))\n",
    "\n",
    "        #cost\n",
    "        total_cost = -np.sum((1/m) * (stoch_y_train * np.log(sigmoid(stoch_X_train, thetas) + epsilon)) + (1 - stoch_y_train) * np.log(1 - sigmoid(stoch_X_train,thetas) + epsilon))\n",
    "\n",
    "        #percent change\n",
    "        percent_change = abs((new_cost - total_cost)/total_cost)\n",
    "        new_cost = total_cost\n",
    "        count_num = count_num + 1\n",
    "\n",
    "    #print(\"Thetas from stochastic gradient descent that minimize the loss function: \", thetas, \"\\n\")\n",
    "    if(kfold == \"kfold\"):\n",
    "        accuracy, precision, recall, F1 = prediction(y_test, X_test, thetas, kfold)\n",
    "        return accuracy, precision, recall, F1\n",
    "    if(kfold == \"no\"):\n",
    "        prediction(y_test, X_test, thetas, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Folds split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(data, numfolds):\n",
    "    dataset = data\n",
    "    data_folds = []\n",
    "    fold_size = int(dataset.shape[0] / numfolds)\n",
    "        \n",
    "    for i in range(numfolds):\n",
    "        fold = []\n",
    "        \n",
    "        #add random data to the folds\n",
    "        while len(fold) < fold_size: \n",
    "            index = random.randrange(dataset.shape[0])\n",
    "            # save data at index to fold \n",
    "            fold.append(dataset.iloc[index].values.tolist())\n",
    "            # delete data line from dataset\n",
    "            dataset = dataset.drop(index,axis = 0)  \n",
    "            dataset.reset_index(drop=True, inplace=True)\n",
    "        data_folds.append(np.asarray(fold))\n",
    "            \n",
    "    return data_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(data, model, kfold, f=5):\n",
    "    data=cv_split(data,f)\n",
    "    result=[]\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    F1 = []\n",
    "    \n",
    "    # determine training and test sets \n",
    "    for i in range(f):\n",
    "        r = list(range(f))\n",
    "        testi = data[i]\n",
    "        r.pop(i)\n",
    "        for j in r :\n",
    "            if j == r[0]:\n",
    "                traini = data[j]\n",
    "            else: \n",
    "                traini=np.concatenate((traini,data[j]), axis=0)\n",
    "        \n",
    "        k_train_x = traini[:, 0:-1]\n",
    "        k_train_y = traini[:, -1]\n",
    "        k_train_y = k_train_y.reshape(k_train_y.shape[0],1)\n",
    "        k_test_x = testi[:, 0:-1]\n",
    "        k_test_y = pd.DataFrame(testi[:, -1])\n",
    "        \n",
    "        if(model == \"batch\"):\n",
    "            accuracy1, precision1, recall1, F11 = logisticBGD(k_train_x, k_train_y, k_test_x, k_test_y, n, m, kfold)\n",
    "            accuracy.append(accuracy1)\n",
    "            precision.append(precision1)\n",
    "            recall.append(recall1)\n",
    "            F1.append(F11)\n",
    "        if(model == \"stochastic\"):\n",
    "            accuracy1, precision1, recall1, F11 = logisticSGD(k_train_x, k_train_y, k_test_y, k_test_x, n, m, kfold)\n",
    "            accuracy.append(accuracy1)\n",
    "            precision.append(precision1)\n",
    "            recall.append(recall1)\n",
    "            F1.append(F11)\n",
    "    print(\"Accuracies: \", np.array(accuracy)*100)\n",
    "    print(\"Precisions: \", np.array(precision)*100)\n",
    "    print(\"Recalls: \", np.array(recall)*100)\n",
    "    print(\"F-measures: \", np.array(F1)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(y_test, X_test, thetas, kfold):\n",
    "    size_test = y_test.shape[0]\n",
    "    predictions = np.zeros(size_test)\n",
    "    TP = FP = TN = FN = accuracy = 0\n",
    "\n",
    "    #find probability for 1 and 0\n",
    "    for a in range(size_test):\n",
    "        p_1 = 1/(1 + math.e ** -(X_test[a] @ thetas))\n",
    "        p_0 = 1 - p_1\n",
    "        if(p_1 > p_0):\n",
    "            predictions[a] = 1\n",
    "        else:\n",
    "            predictions[a] = 0\n",
    "\n",
    "    #find TP, FP, TN, FN\n",
    "    for a in range(size_test):\n",
    "        if (predictions[a] == 1):\n",
    "            if (predictions[a] == y_test.iloc[a][0]):\n",
    "                TP = TP + 1\n",
    "                accuracy = accuracy + 1\n",
    "            else:\n",
    "                FP = FP + 1 \n",
    "        else:\n",
    "            if(predictions[a] == y_test.iloc[a][0]):\n",
    "                TN = TN + 1\n",
    "                accuracy = accuracy + 1\n",
    "            else:\n",
    "                FN = FN + 1\n",
    "\n",
    "    #precision, recall, f measure, accuracy\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    F1 = (2*precision*recall)/(precision + recall)\n",
    "    accuracy = accuracy/size_test\n",
    "    \n",
    "    if(kfold == \"kfold\"):\n",
    "        return accuracy, precision, recall, F1\n",
    "    \n",
    "    else:\n",
    "        print(\"Accuracy: \", accuracy* 100)\n",
    "        print(\"Precision: \", precision * 100)\n",
    "        print(\"Recall: \", recall* 100)\n",
    "        print(\"F-measure: \", F1* 100)\n",
    "        print(\"TP: \", TP,\"; FP: \", FP, \"; TN: \", TN, \"; FN: \", FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Without K-Folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test=train_test_split(s_X,y,test_size=0.33,random_state=0)\n",
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "n = 0.01 #learning rate\n",
    "count = pd.DataFrame()\n",
    "percent_change = 1\n",
    "count_num = 1\n",
    "cost = 1\n",
    "m = X_train.shape[0]\n",
    "#y_train = y_train.to_numpy()\n",
    "epsilon = 1e-5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  77.62542848239326\n",
      "Precision:  73.54635935044526\n",
      "Recall:  86.82745825602969\n",
      "F-measure:  79.6369824163358\n",
      "TP:  1404 ; FP:  505 ; TN:  1087 ; FN:  213\n"
     ]
    }
   ],
   "source": [
    "logisticBGD(X_train, y_train, X_test, y_test, n, m, \"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  77.99937675288253\n",
      "Precision:  74.39742903053026\n",
      "Recall:  85.89981447124305\n",
      "F-measure:  79.73593570608496\n",
      "TP:  1389 ; FP:  478 ; TN:  1114 ; FN:  228\n"
     ]
    }
   ],
   "source": [
    "logisticSGD(X_train, y_train, y_test, X_test, n, m, \"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7880959800560923\n",
      "Precision:  0.7651386530843237\n",
      "Recall:  0.8361162646876933\n",
      "F-measure:  0.7990543735224587\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train,X_test, y_train,y_test=train_test_split(s_X,y,test_size=0.33,random_state=0)\n",
    "y_train = y_train.values.ravel()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "\n",
    "#y_train = y_train.ravel()\n",
    "logistic_regression= LogisticRegression()\n",
    "logistic_regression.fit(X_train,y_train)\n",
    "y_pred=logistic_regression.predict(X_test)\n",
    "y_test = y_test.values\n",
    "y_test = y_test.reshape(3209,)\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ',metrics.precision_score(y_test, y_pred,zero_division=0))\n",
    "print('Recall: ',metrics.recall_score(y_test, y_pred))\n",
    "print('F-measure: ',metrics.f1_score(y_test, y_pred,zero_division=0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results With K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.append(s_X, y, axis=1)\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Batch Gradient Descent, k-folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:  [77.77777778 78.54938272 78.54938272 78.49794239 77.77777778]\n",
      "Precisions:  [73.55595668 76.32763276 72.64150943 75.75757576 74.50805009]\n",
      "Recalls:  [85.42976939 84.63073852 89.62962963 84.26966292 85.        ]\n",
      "F-measures:  [79.04946654 80.26502603 80.24632875 79.78723404 79.40896092]\n"
     ]
    }
   ],
   "source": [
    "kfold(data, \"batch\", \"kfold\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Stochastic Gradient Descent, k-folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:  [78.85802469 77.88065844 78.3436214  78.24074074 78.49794239]\n",
      "Precisions:  [73.58818419 74.13024086 76.67560322 74.52054795 73.82847038]\n",
      "Recalls:  [88.78406709 85.58187436 84.28290766 85.         87.25182863]\n",
      "F-measures:  [80.47505938 79.44550669 80.29948526 79.41605839 79.98084291]\n"
     ]
    }
   ],
   "source": [
    "kfold(data, \"stochastic\", \"kfold\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
