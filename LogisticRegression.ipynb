{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "- Explore the differences between batch and stochastic gradient descent\n",
    "- Implement K-Folds Cross-Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./stroke_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find and fill null values with averages (BMI has 201 null values)\n",
    "avg = data['bmi'].mean()\n",
    "data.bmi = (data.bmi.fillna(avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give numerical values to categorical variables\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th colspan=2>work_type</th>\n",
    "            <th colspan=2>gender</th>\n",
    "            <th colspan=2>Residence_type</th>\n",
    "            <th colspan=2>smoking_status</th>\n",
    "            <th colspan=2>ever_married</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Private</td>\n",
    "            <td>0</td>\n",
    "            <td>Male</td>\n",
    "            <td>0</td>\n",
    "            <td>Urban</td>\n",
    "            <td>0</td>\n",
    "            <td>formerly smoked</td>\n",
    "            <td>0</td>\n",
    "            <td>Yes</td>\n",
    "            <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Self-employed</td>\n",
    "            <td>1</td>\n",
    "            <td>Female</td>\n",
    "            <td>1</td>\n",
    "            <td>Rural</td>\n",
    "            <td>1</td>\n",
    "            <td>never smoked</td>\n",
    "            <td>1</td>\n",
    "            <td>No</td>\n",
    "            <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Govt_job</td>\n",
    "            <td>2</td>\n",
    "            <td>smokes</td>\n",
    "            <td>2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>children</td>\n",
    "            <td>3</td>\n",
    "            <td>Unknown</td>\n",
    "            <td>3</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Never_worked</td>\n",
    "            <td>4</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['work_type'] = data['work_type'].map(\n",
    "    {'Private': 0, 'Self-employed': 1, 'Govt_job': 2, 'children': 3, 'Never_worked': 4})\n",
    "data['gender'] = data['gender'].map({'Male': 0, 'Female': 1})\n",
    "data['Residence_type'] = data['Residence_type'].map({'Urban': 0, 'Rural': 1})\n",
    "data['smoking_status'] = data['smoking_status'].map(\n",
    "    {'formerly smoked': 0, 'never smoked': 1, 'smokes': 2, 'Unknown': 3})\n",
    "data['ever_married'] = data['ever_married'].map({'Yes': 0, 'No': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide dataset into features and labels\n",
    "#drop ID because it's not necessary for analysis\n",
    "X = data[\n",
    "    ['age', 'hypertension', 'heart_disease', 'ever_married', 'Residence_type', 'avg_glucose_level', 'bmi', 'gender',\n",
    "     'work_type', 'smoking_status']]\n",
    "y = data['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinkarnani/.conda/envs/myenv/lib/python3.9/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#replace null values again (1 in gender)\n",
    "X.gender = (X.gender.fillna(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizes the data using the mean and standard deviation\n",
    "mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0, ddof=1)\n",
    "s_X = (X - mean) / std\n",
    "\n",
    "#add bias feature\n",
    "bias = (np.ones((s_X.shape[0], 1)))\n",
    "s_X = np.append(s_X, bias, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "s_X, y = smote.fit_resample(s_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(s_X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "#Initialize the parameters of θ using random values in the range [-1, 1]\n",
    "random.seed(0)\n",
    "thetas = np.random.uniform(-1, 1, 11)\n",
    "\n",
    "#variables \n",
    "n = 0.01  #learning rate\n",
    "count = pd.DataFrame()\n",
    "percent_change = 1\n",
    "count_num = 1\n",
    "cost = 1\n",
    "m = X_train.shape[0]\n",
    "#y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, thetas):\n",
    "    return (1 / (1 + math.e ** -(x @ thetas)))\n",
    "\n",
    "\n",
    "def gradient(X_train, y_train, thetas):\n",
    "    sig = sigmoid(X_train, thetas)\n",
    "    gradient = (X_train.T @ (sig - y_train))\n",
    "    return gradient\n",
    "\n",
    "\n",
    "#predictions\n",
    "def prediction(y_test, X_test, thetas):\n",
    "    size_test = y_test.shape[0]\n",
    "    predictions = np.zeros(size_test)\n",
    "    TP = FP = TN = FN = accuracy = 0\n",
    "\n",
    "    #find probability for 1 and 0\n",
    "    for a in range(size_test):\n",
    "        p_1 = 1 / (1 + math.e ** -(X_test[a] @ thetas))\n",
    "        p_0 = 1 - p_1\n",
    "        if (p_1 > p_0):\n",
    "            predictions[a] = 1\n",
    "        else:\n",
    "            predictions[a] = 0\n",
    "\n",
    "    #find TP, FP, TN, FN\n",
    "    for a in range(size_test):\n",
    "        if (predictions[a] == 1):\n",
    "            if (predictions[a] == y_test.iloc[a]):\n",
    "                TP = TP + 1\n",
    "                accuracy = accuracy + 1\n",
    "            else:\n",
    "                FP = FP + 1\n",
    "        else:\n",
    "            if (predictions[a] == y_test.iloc[a]):\n",
    "                TN = TN + 1\n",
    "                accuracy = accuracy + 1\n",
    "            else:\n",
    "                FN = FN + 1\n",
    "\n",
    "    #precision, recall, f measure, accuracy\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = (2 * precision * recall) / (precision + recall)\n",
    "    accuracy = accuracy / size_test\n",
    "\n",
    "    print(\"Accuracy: \", accuracy * 100)\n",
    "    print(\"Precision: \", precision * 100)\n",
    "    print(\"Recall: \", recall * 100)\n",
    "    print(\"F-measure: \", F1 * 100)\n",
    "    print(\"TP: \", TP, \"; FP: \", FP, \"; TN: \", TN, \"; FN: \", FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticBGD(X_train, y_train, X_test, y_test, n, m):\n",
    "    count_num = 0\n",
    "    new_cost = 0\n",
    "    percent_change = 1\n",
    "    thetas = np.random.uniform(-1, 1, 11)\n",
    "    #Terminate when absolute value change of loss on the data is\n",
    "    #less than 2−23, or after 1500 iterations have passed (whichever occurs first).\n",
    "    while (percent_change > (2 ** -23)):\n",
    "        if (count_num == 1500):\n",
    "            break\n",
    "\n",
    "        #batch gradient descent\n",
    "        thetas = thetas - ((n / m) * gradient(X_train, y_train, thetas))\n",
    "\n",
    "        #cost\n",
    "        total_cost = -np.sum((1 / m) * ((y_train * np.log(sigmoid(X_train, thetas) + epsilon)) + (1 - y_train) * np.log(\n",
    "            1 - sigmoid(X_train, thetas) + epsilon)))\n",
    "\n",
    "        #percent change\n",
    "        percent_change = abs((new_cost - total_cost) / total_cost)\n",
    "        new_cost = total_cost\n",
    "\n",
    "        count_num = count_num + 1\n",
    "\n",
    "    print(\"Thetas from batch gradient descent that minimize the loss function: \", thetas, \"\\n\")\n",
    "    prediction(y_test, X_test, thetas)\n",
    "\n",
    "\n",
    "def logisticSGD(X_train, y_train, y_test, X_test, n, m):\n",
    "    stoch_X_train = X_train\n",
    "    stoch_y_train = y_train\n",
    "    thetas = np.random.uniform(-1, 1, 11)\n",
    "    new_cost = 1\n",
    "    percent_change = 1\n",
    "    count_num = 1\n",
    "\n",
    "    #Terminate when absolute value change of loss on the data is less than 2−23, or after 1500 iterations have passed.\n",
    "    while (percent_change > (2 ** -23)):\n",
    "        if (count_num == 1500):\n",
    "            break\n",
    "\n",
    "        #stochastic gradient descent\n",
    "        index = np.random.permutation(stoch_X_train.shape[0])\n",
    "        stoch_X_train = np.take(stoch_X_train, index, axis=0)\n",
    "        stoch_y_train = np.take(stoch_y_train, index, axis=0)\n",
    "        thetas = thetas - ((n / m) * gradient(stoch_X_train, stoch_y_train, thetas))\n",
    "\n",
    "        #cost\n",
    "        total_cost = -np.sum(\n",
    "            (1 / m) * (stoch_y_train * np.log(sigmoid(stoch_X_train, thetas) + epsilon)) + (1 - stoch_y_train) * np.log(\n",
    "                1 - sigmoid(stoch_X_train, thetas) + epsilon))\n",
    "\n",
    "        #percent change\n",
    "        percent_change = abs((new_cost - total_cost) / total_cost)\n",
    "        new_cost = total_cost\n",
    "        count_num = count_num + 1\n",
    "\n",
    "    print(\"Thetas from stochastic gradient descent that minimize the loss function: \", thetas, \"\\n\")\n",
    "\n",
    "    prediction(y_test, X_test, thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "n = 0.01  #learning rate\n",
    "m = X_train.shape[0]\n",
    "#y_train = y_train.to_numpy()\n",
    "epsilon = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetas from batch gradient descent that minimize the loss function:  [ 1.19378526  0.14676987  0.15097408 -0.30370873 -0.04016311  0.09776613\n",
      "  0.10330068 -0.03987798  0.22335362  0.15987371 -0.67633299] \n",
      "\n",
      "Accuracy:  77.37612963540043\n",
      "Precision:  72.6487036095577\n",
      "Recall:  88.37353123067409\n",
      "F-measure:  79.74330357142857\n",
      "TP:  1429 ; FP:  538 ; TN:  1054 ; FN:  188\n"
     ]
    }
   ],
   "source": [
    "logisticBGD(X_train, y_train, X_test, y_test, n, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetas from stochastic gradient descent that minimize the loss function:  [ 0.84554574  0.19497869  0.18163035 -0.4562947  -0.12663161  0.26991537\n",
      " -0.31632375  0.064809   -0.18497486  0.0518967  -0.64756472] \n",
      "\n",
      "Accuracy:  77.43845434714865\n",
      "Precision:  73.21892875715028\n",
      "Recall:  87.07482993197279\n",
      "F-measure:  79.54802259887006\n",
      "TP:  1408 ; FP:  515 ; TN:  1077 ; FN:  209\n"
     ]
    }
   ],
   "source": [
    "logisticSGD(X_train, y_train, y_test, X_test, n, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7877843564973512\n",
      "Precision:  0.7656072644721907\n",
      "Recall:  0.83426097711812\n",
      "F-measure:  0.7984610831606985\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', metrics.precision_score(y_test, y_pred, zero_division=0))\n",
    "print('Recall: ', metrics.recall_score(y_test, y_pred))\n",
    "print('F-measure: ', metrics.f1_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}